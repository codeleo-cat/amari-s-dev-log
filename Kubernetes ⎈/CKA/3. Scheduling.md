#kubernetes 

# 1. Manual Scheduling
- kubenetes가 yaml 내에 **nodeName**을 자동으로 지정한다.
	- 우선순위 : nodeName > nodeSelector
- 이게 없으면 pod는 pending status로 유지된다.

# 2. Labels and Selectors

✅ **tagging** - nodeSelector는 pod를 **특정 label이 있는 node로 제한**
- k8s는 label과 selector (matchLabels)를 이용해 서로 다른 Objects를 구분한다.

# 3. Taints and Tolerations
✅ **restriction** - Taint와 Toleration은 함께 작동하여 pod가 부절절한 node에 스케줄되지 않게 한다.

- Taint - **node가 pod를 제외**시킬 수 있는 속성 {key:value}
- Toleration (용인) - pod에 적용된다. 이를 통해 스케줄러가 taint가 있는 pod를 스케줄링 할 수 있다. **Taint를 무시하고 특정 노드에 스케줄링될 수 있도록** 하는 설정

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx
  labels:
    env: test
spec:     # Pod의 스펙(사양)을 정의하는 필드
  containers:
  - name: nginx
	image: nginx
    imagePullPolicy: IfNotPresent
  tolerations:
  - key: "example-key"
    operator: "Exists"
    effect: "NoSchedule"
```
# 4. Node Affinity
✅ Pod가 특정 노드에 스케줄링되도록 하는 **제약 조건**을 설정
ex)
```yaml
nodeSelector:
	size:Large
```
- **not** small (use X)
- Large **or** medium (use X)
- nodeSelector보다 세밀하게 조건을 컨트롤할 수 있다.
```yaml
nodeAffinity:
	...
	- matchExpressions:
		- key: size
		  operator : Exists
```

Type
1. **required**DuringSchedulingIgnoredDuringExecution (Pod가 스케줄링될 때 반드시 충족되어야 한다.)
2. **preferred**DuringSchedulingIgnoredDuringExecution (우선 순위가 더 높은 노드를 선택하지만, 조건을 충족하는 노드가 없으면 다른 노드에 배치될 수도 있다.)
3. **required**DuringScheduling**Required**DuringExecution (스케줄링과 실행 중 모두에서 조건이 충족되어야 한다.)
# 5. Resource Requirements and limits

# 6. DaemonSets
✅ **노드별로 Pod를 배포할 때 사용**

- Node별로 Pod 정보를 수집해야 할 때
- Node에 필수로 실행되어야하는 Pod가 있을 때
- cluster에 변화가 생겼다 > DaemonSet이 알아서 한다. ex) networking, kube-proxy
- created by kube-API server
- deploy monitoring Agents, Logging Agents on nodes
# 7. Static Pods
✅ pod **managed directly by the kubelet** daemon on a specific node, without the API server

- pod-manifest
- **Kubernetes API 서버없이** created by the kubelet
- deploy control plane components as static pods
- kubelet.service 파일을 제공하고, staticPodPath를 제공할 수도 있다. StaticPodPath 경로의 yaml 삭제해야 삭제됨.
- 1) 정적 포드 파일을 통해서. 2) HTTP API endpoint를 통해서.
- 시스템이 다운된다 하더라도, 자동으로 kubelet이 재 시작시킬 것이다.
# 8. Multiple Schedulers
```yaml

apiVersion:
kind: KubeScheduleConfiguration
profiles:
- schedulerName : XXX

```

Scheduling Queue > filtering > Scoring > Binding
K8s can determine - what plugin goes where 

----
# Practice Test

**Manual Scheduling** (replace)
```yaml
# pod delete + 다시 node에 할당하여 create


# 지속적인 변화 상태 monitor => --watch
```

**Labels and Selectors** (wc -l)
```yaml
# word count -list (wc -l)

```

**Taints and Tolerations**
```yaml
# kubectl taint를 사용하여 노드에 테인트을 추가한다. 일치하는 toleration 이 없으면 pod를 node01에 스케줄할 수 없다.
kubectl taint no node01 spray=mortein:NoSchedule

--dry-run=client -o yaml > example.yaml

# untaint (맨 뒤 - 를 붙임.)
kubectl taint no controlplane node-role.kubernetes.io/control-plane:NoSchedule-

```

**Node Affinity**
```yaml

kubectl label no node01 color=blue

```

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: blue
spec:
  replicas: 3
  selector:
    matchLabels:
      run: nginx
  template:
    metadata:
      labels:
        run: nginx
    spec:
      containers:
      - image: nginx
        imagePullPolicy: Always
        name: nginx
      affinity: # Pod의 배치 정책을 정의
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution: # 이 조건은 스케줄링 시 반드시 충족되어야 함.
            nodeSelectorTerms:
            - matchExpressions:
              - key: color         # node의 `color` 레이블이 `blue`인 경우에만 Pod가 스케줄링됨.
                operator: In
                values:
                - blue
```

**Resource Requirements and limits**
```yaml
# 존재하는 po의 declarative yaml 
kubectl get po elephant -o yaml > elephant.yaml

# 바로 edit
kubectl edit po elephant

kubectl replace -f elephant.yaml --force
# pod "elephant" deleted
# pod/elephant replaced
```

**DaemonSets**
```yaml
kubectl get daemonsets -A

# deploy 에서 생성함.
kubectl create deploy elasticsearch --image=registry.k8s.io/fluentd-elasticsearch:1.20 -n kube-system --dry-run=client -o yaml > fluentd.yaml

# yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  creationTimestamp: null
  labels:
    app: elasticsearch
  name: elasticsearch
  namespace: kube-system
spec:
  selector:
    matchLabels:
      app: elasticsearch
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: elasticsearch
    spec:
      containers:
      - image: registry.k8s.io/fluentd-elasticsearch:1.20
        name: fluentd-elasticsearch
```

**Static Pods**

- file path - **/etc/kubernetes/manifests**
```yaml

# How many static pods exist in this cluster?
k get po -A

k get po kube-apiserver-controlplane -n kube-system

k get po -A
# controlplane 으로 끝나지 않는 것.

cat /var/lib/kubelet/config.yaml
ls /etc/kubernetes/manifests

k run static-busybox --image=busybox --dry-run=client -o yaml --command --sleep 1000 > static-busybox.yaml
cp static-busybox.yaml /etc/kubernetes/manifests/

# edit
vi /etc/kubernetes/manifests/staic-busybox.yaml

# find and delete it
k get po

k delete po static-greenbox-node01
ls /etc/kubernetes/manifests

k get nodes -o wide
ssh 10.38.102.8. # node01 접속
ls /etc/kubernetes/manifests
cat /var/lib/

# staticPodPath : /etc/......

cd /etc/....
rm greenbox.yaml
exit
```

**Multiple Schedulers** (event)
```yaml
k get po -A

k describe po $pod_name -n $ns | grep i image

# service account (sa)
k get sa my-scheduler -n kube-system

 k create configmap my-scheduler-config --from-file=/root/my-scheduler-config.yaml -n kube-system

# deploy an additional scheduler
k describe po kube-scheduler-controlplane -n kube-system | grep -i image

# previous
apiVersion: v1 
kind: Pod 
metadata:
  name: nginx 
spec:
  containers:
  - image: nginx
    name: nginx

# add custom-scheduler
apiVersion: v1 
kind: Pod 
metadata:
  name: nginx 
spec:
  schedulerName: my-scheduler
  containers:
  - image: nginx
    name: nginx

k create -f nginx-pod.yaml 
```