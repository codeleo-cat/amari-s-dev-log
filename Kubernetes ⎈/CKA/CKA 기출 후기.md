2024/08/17 ì‹œí—˜

CKA í›„ê¸°.
ë­ë„ê¹Œ ì–´ì°Œë˜ì—ˆë“  ì‹œí—˜ì€ ëì´ ë‚¬êµ¬ë‚˜ ì‹¶ë‹¤.
í™•ì‹¤íˆ ì•½í•œ ë¶€ë¶„ì€ ì•½í•œ ë¶€ë¶„ì´ê³ , ì˜ˆìƒì¹˜ ëª»í•œ ë³€ìˆ˜ë„ ìˆì—ˆë‹¤.
ì¼ë‹¨ ëª¨ë‹ˆí„° íŒ¨ë„ì´ ë‚˜ê°”ê³  ã… ã…  ê·¸ëƒ¥ ë‚´ ë¶€ì£¼ì˜ì— ëŒ€í•œ ê°’ì„ ì¹˜ë£¬ë‹¤ê³  ìƒê°í•˜ì.
etcd backupì—ì„œ íŒŒì¼ì´ ì—†ë‹¤ê³  ëœ¬ë‹¤ë˜ì§€
cluster upgrade ì—­ì‹œ ë¬´ë‚œí•˜ê²Œ í•  ì¤„ ì•Œì•˜ëŠ”ë°..
ê·¸ë˜ë„ CKAê°€ ë¬¸ì œì€í–‰ ì‹ì´ë¼ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆì–´ ë‹¤í–‰ì´ì—ˆë‹¤.
ê¸°ì–µì´ ì¦ë°œë˜ê¸° ì „ì— ê¸°ë¡í•´ë‘ì–´ì•¼ ê² ë‹¤.
ê²°ê³¼ë„ ì¤‘ìš”í•˜ì§€ë§Œ ê³¼ì •ë„ ì¤‘ìš”í•˜ë‹¤ê³  ëŠë‚€ ì‹œí—˜ ì¤€ë¹„ ê¸°ê°„ì´ì—ˆë‹¤.
ë”± ë‚´ê°€ ëœ ë´¤ë˜ ë¶€ë¶„ì—ì„œ ì—­ì‹œë‚˜ í—·ê°ˆë¦¬ëŠ” ê¸°ë¶„ì´ ë§ì´ ë“¤ì—ˆë‹¤.
ì–´ì°Œë˜ì—ˆë“  ë¶€ë‹´ì€ ì´ì œ ì—†ë‹¤.

---
ì¤€ë¹„ë¬¼
ì—¬ê¶Œì„ ì¤€ë¹„í•´ì„œ ë¯¸ë¦¬ ë“±ë¡í•´ë‘ì„¸ìš”.
ê°€ì¥ í™•ì‹¤í•œ ë°©ë²•ì…ë‹ˆë‹¤.

í›„ê¸°
ìƒê°ë³´ë‹¤ PSI í™˜ê²½ì´ ê·¸ë ‡ê²Œ ëŠë¦¬ì§€ëŠ” ì•Šì•˜ìŠµë‹ˆë‹¤.
ì—°ê²° ì—­ì‹œ ì¤‘ê°„ì— 1ë¶„ ì •ë„ ëŠê¸°ê¸°ëŠ” í–ˆìœ¼ë‚˜ ì‹œí—˜ì— ì§€ì¥ì„ ì¤„ ì •ë„ëŠ” ì•„ë‹ˆì—ˆìŠµë‹ˆë‹¤.
ê·¸ë¦¬ê³  17ë¬¸ì œë¥¼ í‘¸ëŠ”ë°ì— 120ë¶„ì´ ì£¼ì–´ì§€ëŠ”ë° ì‹œê°„ì€ ì¶©ë¶„í•˜ê²Œ ëŠê»´ì§‘ë‹ˆë‹¤.
ì €ëŠ” ì•½ 90ë¶„ ì •ë„ê°€ ê±¸ë ¸ìŠµë‹ˆë‹¤.
ë‹¤ë§Œ ì‹œí—˜ í™˜ê²½ ì„¸íŒ… & ê°ë…ê´€ì˜ í™˜ê²½ ê²€ì‚¬ì— ì•½ 20ë¶„ ë„˜ê²Œ ì†Œìš”ë˜ì—ˆìŠµë‹ˆë‹¤.
ë°© ì „ì²´ë¥¼ ì›¹ìº ìœ¼ë¡œ ë¹„ì¶”ê³ , ê·€ë„ ë¹„ì¶”ê³ , ì–‘ì†ê³¼ íŒ”ë„ ë“¤ì–´ì•¼ í•˜ê³ 
íˆ¬ëª…í•œ ì»µì— ë‹´ê¸´ ë¬¼ê³¼ ë§ˆìš°ìŠ¤ ì •ë„ë§Œ í—ˆìš©ë©ë‹ˆë‹¤.
ì°¸ê³ ë¡œ ì±…ìƒ ë°‘ë„ ê¹¨ë—í•´ì•¼ í•©ë‹ˆë‹¤.


ì¤€ë¹„ ê³¼ì •
- Udemy ê°•ì˜. Kubernetes ê°•ì˜ì˜ ê½ƒì´ì£ .
- 30ë¬¸ì œ í’€ì´

ë¹ ë¥¸ ì·¨ë“ì„ ì›í•œë‹¤ë©´
- Mock Exam 1~3 ì€ ê¼­ í’€ì–´ë³´ëŠ” ê²ƒì„ ì¶”ì²œë“œë¦¬ë©°
- ë¬¸ì œ ì€í–‰ì„ ì™¸ìš°ëŠ” ê²ƒì„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤.

---
ê¸°ì–µë‚˜ëŠ” ì‹œí—˜ ë¬¸ì œ ìœ í˜•
1. clusterë‚´ì˜ master nodeë§Œ(worker nodeëŠ” x) kubeadm,kubelet,kubectlì„ íŠ¹ì • versionìœ¼ë¡œ update
(1.30.0 -> 1.30.1)
- ì—¬ê¸°ì„œ ì–´ë–¤ ë¬¸ì œê°€ ìƒê²¨ì„œ ì•ˆë˜ì—ˆìŠµë‹ˆë‹¤. 

2. clusterë‚´ì—ì„œ unready ìƒíƒœì¸ worker nodeì˜ ë¬¸ì œ í•´ê²°í•˜ê³ , ready ìƒíƒœë¡œ ë°”ê¾¸ê¸°
```sh
k get no

# node ìƒíƒœê°€ unReady ì¸ ë…¸ë“œë¡œ ì ‘ì†
ssh `node`

systemctl status kubelet # ë¬¸ì œê°€ ìˆì„ ê²ƒ

systemctl start kubelet # ë‹¤ì‹œ ì‹œì‘ì‹œì¼œì¤€ë‹¤.
```

**1. systemctl start kubelet**
â€¢ **ë™ì‘**: kubelet ì„œë¹„ìŠ¤ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.
â€¢ **ì„¤ëª…**: kubelet ì„œë¹„ìŠ¤ê°€ ì¤‘ì§€ë˜ì–´ ìˆëŠ” ìƒíƒœì—ì„œ ì´ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ë©´ kubeletì´ ì‹œì‘ë©ë‹ˆë‹¤. ì„œë¹„ìŠ¤ê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ê²½ìš°ì—ëŠ” ë³€í™” X

**2. systemctl restart kubelet**
â€¢ **ë™ì‘**: kubelet ì„œë¹„ìŠ¤ë¥¼ ì¬ì‹œì‘í•©ë‹ˆë‹¤. (í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ kubelet ì„œë¹„ìŠ¤ë¥¼ ì¤‘ì§€í•œ ë‹¤ìŒ, ë‹¤ì‹œ ì‹œì‘)

3. clusterë‚´ì—ì„œ schedulableí•œ nodeì˜ ê°¯ìˆ˜ ì„¸ê¸°(unscheduled taint ëœ node ì œì™¸í•˜ê³ ) > íŠ¹ì • íŒŒì¼ë¡œ ì €ì¥
k describe no | grep -i taint
Taints: Â  Â  Â  Â  Â  Â  unscheduled
Taints: Â  Â  Â  Â  Â  Â  <none>
Taints: Â  Â  Â  Â  Â  Â  <none>
echo 1 >> íŠ¹ì • íŒŒì¼

1. [í’€ì´](https://cumulus.tistory.com/106)
- From the pod label name=overloaded-cpu, find pods running high CPU workloads and name of the pod consuming most CPU to the file /var/CKA2024/cpu_load_pod.txt

```sh
k top po -l name=overloaded-cpu --sort-by=cpu
(`A` pod)

echo `A pod name` >> /var/CKA2024/cpu_load_pod.txt
```

k get po --show-labels
k top po
ì œì¼ ë†’ì€ Pod name >> íŒŒì¼ë¡œ ì €ì¥
    
[í’€ì´](https://www.examtopics.com/discussions/cncf/view/126449-exam-cka-topic-1-question-19-discussion/)
Create a new NetworkPolicy named allow-port-from-namespace in the existing namespace echo.  
  
Ensure that the new NetworkPolicy allows Pods in namespace internal to connect to port 9200/tcp of Pods in namespace echo.  
  
Further ensure that the new NetworkPolicy:  
  
â€¢ does not allow access to Pods, which don't listen on port 9200/tcp  
â€¢ does not allow access from Pods, which are not in namespace internal

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-port-from-namespace
  namespace: echo
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          kubernetes.io/metadata.name: internal   
    ports:
    - protocol: TCP
      port: 9200
```
        
3. etcd backup and restore
ê¶Œí•œ ë¬¸ì œë¡œ backup saveê°€ ì•ˆë¨.
/etc/kubernetes/manifests/etcd.yaml
sudo
    
4. logìš© sidecar container ì¶”ê°€
[ë”°ë°°ì¿ ](https://cumulus.tistory.com/99)
[í’€ì´](https://www.examtopics.com/discussions/cncf/view/87619-exam-cka-topic-1-question-13-discussion/)
    
        
5. ingress
    
    - "/hi" prefixì— "hi" service ì—°ê²°í•˜ê¸°
        
6. [í’€ì´](https://cumulus.tistory.com/105)
- Reconfigure the existing deployment front-end and add a port specification named http exposing port 80/tcp of the existing container nginx.
- Create a new service named front-end-svc exposing the container port http
- Configure the new service to also expose the individual Pods visa a NodePort on the nodes on which they are scheduled

k get deploy front-end -o yaml > front-end.yaml
vi front-end.yaml
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: front-end
spec:
  replicas: 2
  selector:
    matchLabels:
      run: nginx
  template:
    metadata:
      labels:
        run: nginx
    spec:
      containers:
      - image: nginx
        name: http
        ports:
        - containerPort: 80
          name: http
```
ë³€ê²½ ğŸ”½
```yaml
apiVersion: v1
kind: Service
metadata:
  name: front-end-svc
spec:
  type: NodePort
  selector:
    run: nginx
  ports:
  - name: http
    protocol: TCP
    port: 80
    targetPort: http
```
k delete deploy front-end
k apply -f front-end.yaml


7. serviceaccount ìƒì„±, clusterrole, clusterrolebinding ìƒì„±
ci-cd token

```sh
k create sa
k create clusterrole
k create clusterrolebinding
k auth can -i
```
    
8. ì¡´ì¬í•˜ëŠ” deploymentì˜ replica ê°œìˆ˜ ì¦ê°€
    
9. pv ìƒì„±(hostpath)
    
10. pvc ìƒì„± í›„(storage class) í•´ë‹¹ pvcë¥¼ ì‚¬ìš©í•˜ëŠ” pod ìƒì„±, ê·¸ë¦¬ê³  ì´í›„ì— pvcë¥¼ ìˆ˜ì •í•´ì„œ capacity ëŠ˜ë¦¬ê¸°(10Mi -> 70Mi)
    
11. multi container(í•œ podë‚´ì— nginx, memcached ë‘ê°œì˜ container ì¶”ê°€)
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: lab004
spec:
  containers:
  - image: nginx
    name: nginx
  - image: memcached
    name: memcached
```

12. nodeSelector, íŠ¹ì • labelë¥¼ ì§€ë‹Œ nodeì— podê°€ schedule ë  ìˆ˜ ìˆê²Œ ì„¤ì •
nodeë¼ë²¨ì´ 'disk=running'ì´ ìˆëŠ” nodeì—ë§Œ Podë¥¼ scheduleí•˜ëŠ” ë¬¸ì œ  
Affinity ì„¤ì •ìœ¼ë¡œ Pod Schedule ì§„í–‰
- Schedule a pod as follows:
Â  . Name : eshop-store
Â  . Image : nginx
Â  . Node selector : disk=running

k get no --show-labels
kubectl run eshop-store --image=nginx --dry-run=client -o yaml > eshop-store.yaml

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
    - name: nginx
      image: nginx:1.14.2
  nodeSelector: disk=running
```

13
- Monitor the logs of pod `custom-app` and: Extract log lines corresponding to error `file not found`
- Write them to /var/CKA2024/pod_log.
```sh
k logs `custom-app`  | grep -i `file not found` >> /var/CKA2024/pod_log
```
ì—¬ê¸°ì„œ pod nameê³¼ error ì¢…ë¥˜ë§Œ ë‹¬ë¼ì§.


14.
Set the node labelled with name=**ek8s-node-1**Â as unavailable and reschedule all the pods running on it.
```sh
kubectl drain ek8s-node-1 --delete-local-data --ignore-daemonsets --force
```

ë¬¸ì œì€í–‰ì…ë‹ˆë‹¤.

https://github.com/sandistorm/CKA-Certified-Kubernetes-Administrator-2022/blob/main/CKA%20Exam.md